{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Prosumidor/courses/blob/master/Actividad_1_Redes_Neuronales_Artificiales_ANN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iiDzBoKGwmMZ"
      },
      "source": [
        "# REDES NEURONALES\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeO2xVqBv1fx"
      },
      "source": [
        "## Introducción"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhzeF2BVvvi7"
      },
      "source": [
        "\n",
        "\n",
        "En esta actividad vamos a utilizar una red neuronal para clasificar imágenes de prendas de ropa. Para ello, utilizaremos Keras con TensorFlow.\n",
        "\n",
        "El dataset a utilizar es Fashion MNIST, un problema sencillo con imágenes pequeñas de ropa, pero más interesante que el dataset de MNIST. Puedes consultar más información sobre el dataset en [este enlace](https://github.com/zalandoresearch/fashion-mnist).\n",
        "\n",
        "El código utilizado para contestar tiene que quedar claramente reflejado en el Notebook. Puedes crear nuevas celdas si así lo deseas para estructurar tu código y sus salidas. A la hora de entregar el notebook, **asegúrate de que los resultados de ejecutar tu código han quedado guardados**. Por ejemplo, a la hora de entrenar una red neuronal tiene que verse claramente un log de los resultados de cada epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gSHr268SwmMa"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zScMKU2OKSPD"
      },
      "source": [
        "En primer lugar vamos a importar el dataset Fashion MNIST (recordad que este es uno de los dataset de entranamiento que estan guardados en keras) que es el que vamos a utilizar en esta actividad:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4voG2hxxG4h3"
      },
      "outputs": [],
      "source": [
        "mnist = tf.keras.datasets.fashion_mnist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JphLsCvgKrzb"
      },
      "source": [
        "Llamar a **load_data** en este dataset nos dará dos conjuntos de dos listas, estos serán los valores de entrenamiento y prueba para los gráficos que contienen las prendas de vestir y sus etiquetas.\n",
        "\n",
        "Nota: Aunque en esta actividad lo veis de esta forma, también lo vais a poder encontrar como 4 variables de esta forma: training_images, training_labels, test_images, test_labels = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1muD4PHEG4h6",
        "outputId": "d82608bd-857c-4bed-f42a-dc36cf6a11d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWGpJqVVLT3Y"
      },
      "source": [
        "Antes de continuar vamos a dar un vistazo a nuestro dataset, para ello vamos a ver una imagen de entrenamiento y su etiqueta o clase."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 933
        },
        "id": "t5a5PlswG4h8",
        "outputId": "897fce8f-5232-4108-def8-39cb4c93b7dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n",
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   1   0   0  13  73   0   0   1   4   0   0   0   0   1   1   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  36 136 127  62  54   0   0   0   1   3   4   0   0   3]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   6   0 102 204 176 134 144 123  23   0   0   0   0  12  10   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 155 236 207 178 107 156 161 109  64  23  77 130  72  15]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   1   0  69 207 223 218 216 216 163 127 121 122 146 141  88 172  66]\n",
            " [  0   0   0   0   0   0   0   0   0   1   1   1   0 200 232 232 233 229 223 223 215 213 164 127 123 196 229   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 183 225 216 223 228 235 227 224 222 224 221 223 245 173   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 193 228 218 213 198 180 212 210 211 213 223 220 243 202   0]\n",
            " [  0   0   0   0   0   0   0   0   0   1   3   0  12 219 220 212 218 192 169 227 208 218 224 212 226 197 209  52]\n",
            " [  0   0   0   0   0   0   0   0   0   0   6   0  99 244 222 220 218 203 198 221 215 213 222 220 245 119 167  56]\n",
            " [  0   0   0   0   0   0   0   0   0   4   0   0  55 236 228 230 228 240 232 213 218 223 234 217 217 209  92   0]\n",
            " [  0   0   1   4   6   7   2   0   0   0   0   0 237 226 217 223 222 219 222 221 216 223 229 215 218 255  77   0]\n",
            " [  0   3   0   0   0   0   0   0   0  62 145 204 228 207 213 221 218 208 211 218 224 223 219 215 224 244 159   0]\n",
            " [  0   0   0   0  18  44  82 107 189 228 220 222 217 226 200 205 211 230 224 234 176 188 250 248 233 238 215   0]\n",
            " [  0  57 187 208 224 221 224 208 204 214 208 209 200 159 245 193 206 223 255 255 221 234 221 211 220 232 246   0]\n",
            " [  3 202 228 224 221 211 211 214 205 205 205 220 240  80 150 255 229 221 188 154 191 210 204 209 222 228 225   0]\n",
            " [ 98 233 198 210 222 229 229 234 249 220 194 215 217 241  65  73 106 117 168 219 221 215 217 223 223 224 229  29]\n",
            " [ 75 204 212 204 193 205 211 225 216 185 197 206 198 213 240 195 227 245 239 223 218 212 209 222 220 221 230  67]\n",
            " [ 48 203 183 194 213 197 185 190 194 192 202 214 219 221 220 236 225 216 199 206 186 181 177 172 181 205 206 115]\n",
            " [  0 122 219 193 179 171 183 196 204 210 213 207 211 210 200 196 194 191 195 191 198 192 176 156 167 177 210  92]\n",
            " [  0   0  74 189 212 191 175 172 175 181 185 188 189 188 193 198 204 209 210 210 211 188 188 194 192 216 170   0]\n",
            " [  2   0   0   0  66 200 222 237 239 242 246 243 244 221 220 193 191 179 182 182 181 176 166 168  99  58   0   0]\n",
            " [  0   0   0   0   0   0   0  40  61  44  72  41  35   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAg2klEQVR4nO3de2zV9f3H8ddpoYdC28NK6U3KVRAjFzeEWlF+KhXoEiNCJl7+gM1LZMUMmdOwqOhcUseSzbgxTLYFZiLeEoFolAWLlDkuDoQgmSOAKGBpucyeU3qn/f7+IHZWrp+P5/Tdlucj+Sb0nO+L78cv3/blt+f03VAQBIEAAOhkSdYLAABcniggAIAJCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmOhlvYBva2trU2VlpdLT0xUKhayXAwBwFASBamtrlZ+fr6Sk89/ndLkCqqysVEFBgfUyAADf0eHDhzVo0KDzPt/lvgWXnp5uvQQAQBxc7Ot5wgpo2bJlGjp0qPr06aPCwkJ99NFHl5Tj224A0DNc7Ot5Qgro9ddf16JFi7RkyRJ9/PHHGj9+vKZPn65jx44l4nAAgO4oSIBJkyYFpaWl7R+3trYG+fn5QVlZ2UWz0Wg0kMTGxsbG1s23aDR6wa/3cb8Dam5u1o4dO1RcXNz+WFJSkoqLi7Vly5az9m9qalIsFuuwAQB6vrgX0IkTJ9Ta2qqcnJwOj+fk5Kiqquqs/cvKyhSJRNo33gEHAJcH83fBLV68WNFotH07fPiw9ZIAAJ0g7j8HlJWVpeTkZFVXV3d4vLq6Wrm5uWftHw6HFQ6H470MAEAXF/c7oJSUFE2YMEHl5eXtj7W1tam8vFxFRUXxPhwAoJtKyCSERYsWae7cubruuus0adIkvfDCC6qrq9OPf/zjRBwOANANJaSA5syZo+PHj+vpp59WVVWVrr32Wq1bt+6sNyYAAC5foSAIAutFfFMsFlMkErFeBgDgO4pGo8rIyDjv8+bvggMAXJ4oIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJiggAIAJCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJiggAIAJCggAYIICAgCYoIAAACYoIACAiV7WCwC6klAo5JwJgiABKzlbenq6c+bGG2/0OtZ7773nlXPlc76Tk5OdM6dPn3bOdHU+585Xoq5x7oAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJiggAIAJCggAYIICAgCYYBgp8A1JSe7/T9ba2uqcufLKK50zDzzwgHOmoaHBOSNJdXV1zpnGxkbnzEcffeSc6czBoj4DP32uIZ/jdOZ5cB0AGwSB2traLrofd0AAABMUEADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMAEBQQAMEEBAQBMMIwU+AbXoYuS3zDSW2+91TlTXFzsnDly5IhzRpLC4bBzpm/fvs6Z2267zTnzl7/8xTlTXV3tnJHODNV05XM9+EhLS/PKXcqQ0G+rr6/3OtbFcAcEADBBAQEATMS9gJ555hmFQqEO2+jRo+N9GABAN5eQ14CuueYavf/++/87SC9eagIAdJSQZujVq5dyc3MT8VcDAHqIhLwGtG/fPuXn52v48OG67777dOjQofPu29TUpFgs1mEDAPR8cS+gwsJCrVy5UuvWrdPy5ct18OBB3XTTTaqtrT3n/mVlZYpEIu1bQUFBvJcEAOiC4l5AJSUl+tGPfqRx48Zp+vTpevfdd1VTU6M33njjnPsvXrxY0Wi0fTt8+HC8lwQA6IIS/u6A/v37a9SoUdq/f/85nw+Hw14/9AYA6N4S/nNAp06d0oEDB5SXl5foQwEAupG4F9Bjjz2miooKff7559q8ebPuvPNOJScn65577on3oQAA3VjcvwV35MgR3XPPPTp58qQGDhyoG2+8UVu3btXAgQPjfSgAQDcW9wJ67bXX4v1XAp2mubm5U44zceJE58zQoUOdMz7DVSUpKcn9myN///vfnTPf//73nTNLly51zmzfvt05I0mffPKJc+bTTz91zkyaNMk543MNSdLmzZudM1u2bHHaPwiCS/qRGmbBAQBMUEAAABMUEADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMAEBQQAMJHwX0gHWAiFQl65IAicM7fddptz5rrrrnPOnO/X2l9Iv379nDOSNGrUqE7J/Otf/3LOnO+XW15IWlqac0aSioqKnDOzZs1yzrS0tDhnfM6dJD3wwAPOmaamJqf9T58+rX/84x8X3Y87IACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJiggAIAJCggAYIICAgCYoIAAACYoIACAiVDgM/43gWKxmCKRiPUykCC+U6o7i8+nw9atW50zQ4cOdc748D3fp0+fds40Nzd7HctVY2Ojc6atrc3rWB9//LFzxmdat8/5njFjhnNGkoYPH+6cueKKK7yOFY1GlZGRcd7nuQMCAJiggAAAJiggAIAJCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgopf1AnB56WKzb+Piq6++cs7k5eU5ZxoaGpwz4XDYOSNJvXq5f2lIS0tzzvgMFk1NTXXO+A4jvemmm5wzN9xwg3MmKcn9XiA7O9s5I0nr1q3zyiUCd0AAABMUEADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMAEBQQAMEEBAQBMMIwU+I769u3rnPEZPumTqa+vd85IUjQadc6cPHnSOTN06FDnjM9A21Ao5JyR/M65z/XQ2trqnPEdsFpQUOCVSwTugAAAJiggAIAJ5wLatGmTbr/9duXn5ysUCmnNmjUdng+CQE8//bTy8vKUmpqq4uJi7du3L17rBQD0EM4FVFdXp/Hjx2vZsmXnfH7p0qV68cUX9dJLL2nbtm3q16+fpk+f7vWLpwAAPZfzmxBKSkpUUlJyzueCINALL7ygJ598UnfccYck6eWXX1ZOTo7WrFmju++++7utFgDQY8T1NaCDBw+qqqpKxcXF7Y9FIhEVFhZqy5Yt58w0NTUpFot12AAAPV9cC6iqqkqSlJOT0+HxnJyc9ue+raysTJFIpH3rSm8RBAAkjvm74BYvXqxoNNq+HT582HpJAIBOENcCys3NlSRVV1d3eLy6urr9uW8Lh8PKyMjosAEAer64FtCwYcOUm5ur8vLy9sdisZi2bdumoqKieB4KANDNOb8L7tSpU9q/f3/7xwcPHtSuXbuUmZmpwYMHa+HChfr1r3+tkSNHatiwYXrqqaeUn5+vmTNnxnPdAIBuzrmAtm/frltuuaX940WLFkmS5s6dq5UrV+rxxx9XXV2dHnroIdXU1OjGG2/UunXr1KdPn/itGgDQ7YUCn8l+CRSLxRSJRKyXgQTxGQrpMxDSZ7ijJKWlpTlndu7c6ZzxOQ8NDQ3OmXA47JyRpMrKSufMt1/7vRQ33HCDc8Zn6KnPgFBJSklJcc7U1tY6Z3y+5vm+YcvnGr///vud9m9tbdXOnTsVjUYv+Lq++bvgAACXJwoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJiggAIAJCggAYIICAgCYoIAAACYoIACACedfxwB8Fz7D15OTk50zvtOw58yZ45w532/7vZDjx487Z1JTU50zbW1tzhlJ6tevn3OmoKDAOdPc3Oyc8Znw3dLS4pyRpF693L9E+vw7DRgwwDmzbNky54wkXXvttc4Zn/NwKbgDAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJiggAIAJCggAYIJhpOhUPkMNfQZW+tqzZ49zpqmpyTnTu3dv50xnDmXNzs52zjQ2NjpnTp486ZzxOXd9+vRxzkh+Q1m/+uor58yRI0ecM/fee69zRpJ++9vfOme2bt3qdayL4Q4IAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJiggAIAJCggAYIICAgCYoIAAACYoIACAict6GGkoFPLK+QyFTEpy73qf9bW0tDhn2tranDO+Tp8+3WnH8vHuu+86Z+rq6pwzDQ0NzpmUlBTnTBAEzhlJOn78uHPG5/PCZ0iozzXuq7M+n3zO3bhx45wzkhSNRr1yicAdEADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMAEBQQAMEEBAQBMUEAAABM9ZhipzzC/1tZWr2N19YGaXdmUKVOcM7Nnz3bOTJ482TkjSfX19c6ZkydPOmd8Bov26uX+6ep7jfucB5/PwXA47JzxGWDqO5TV5zz48LkeTp065XWsWbNmOWfefvttr2NdDHdAAAATFBAAwIRzAW3atEm333678vPzFQqFtGbNmg7Pz5s3T6FQqMM2Y8aMeK0XANBDOBdQXV2dxo8fr2XLlp13nxkzZujo0aPt26uvvvqdFgkA6HmcX9UsKSlRSUnJBfcJh8PKzc31XhQAoOdLyGtAGzduVHZ2tq666irNnz//gu8SampqUiwW67ABAHq+uBfQjBkz9PLLL6u8vFy/+c1vVFFRoZKSkvO+HbSsrEyRSKR9KygoiPeSAABdUNx/Dujuu+9u//PYsWM1btw4jRgxQhs3btTUqVPP2n/x4sVatGhR+8exWIwSAoDLQMLfhj18+HBlZWVp//7953w+HA4rIyOjwwYA6PkSXkBHjhzRyZMnlZeXl+hDAQC6EedvwZ06darD3czBgwe1a9cuZWZmKjMzU88++6xmz56t3NxcHThwQI8//riuvPJKTZ8+Pa4LBwB0b84FtH37dt1yyy3tH3/9+s3cuXO1fPly7d69W3/7299UU1Oj/Px8TZs2Tc8995zXzCcAQM8VCnyn9CVILBZTJBKxXkbcZWZmOmfy8/OdMyNHjuyU40h+Qw1HjRrlnGlqanLOJCX5fXe5paXFOZOamuqcqaysdM707t3bOeMz5FKSBgwY4Jxpbm52zvTt29c5s3nzZudMWlqac0byG57b1tbmnIlGo84Zn+tBkqqrq50zV199tdexotHoBV/XZxYcAMAEBQQAMEEBAQBMUEAAABMUEADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMBE3H8lt5Xrr7/eOfPcc895HWvgwIHOmf79+ztnWltbnTPJycnOmZqaGueMJJ0+fdo5U1tb65zxmbIcCoWcM5LU0NDgnPGZznzXXXc5Z7Zv3+6cSU9Pd85IfhPIhw4d6nUsV2PHjnXO+J6Hw4cPO2fq6+udMz4T1X0nfA8ZMsQrlwjcAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMAEBQQAMEEBAQBMUEAAABMUEADABAUEADDRZYeRJiUlOQ2UfPHFF52PkZeX55yR/IaE+mR8hhr6SElJ8cr5/Df5DPv0EYlEvHI+gxqff/5554zPeZg/f75zprKy0jkjSY2Njc6Z8vJy58xnn33mnBk5cqRzZsCAAc4ZyW8Qbu/evZ0zSUnu9wItLS3OGUk6fvy4Vy4RuAMCAJiggAAAJiggAIAJCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgIhQEQWC9iG+KxWKKRCK67777nIZk+gyEPHDggHNGktLS0jolEw6HnTM+fIYnSn4DPw8fPuyc8RmoOXDgQOeM5DcUMjc31zkzc+ZM50yfPn2cM0OHDnXOSH7X64QJEzol4/Nv5DNU1PdYvsN9XbkMa/4mn8/366+/3mn/trY2ffnll4pGo8rIyDjvftwBAQBMUEAAABMUEADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMAEBQQAMNHLegHnc/z4caeheT5DLtPT050zktTU1OSc8Vmfz0BIn0GIFxoWeCH//e9/nTNffPGFc8bnPDQ0NDhnJKmxsdE5c/r0aefM6tWrnTOffPKJc8Z3GGlmZqZzxmfgZ01NjXOmpaXFOePzbySdGarpymfYp89xfIeR+nyNGDVqlNP+p0+f1pdffnnR/bgDAgCYoIAAACacCqisrEwTJ05Uenq6srOzNXPmTO3du7fDPo2NjSotLdWAAQOUlpam2bNnq7q6Oq6LBgB0f04FVFFRodLSUm3dulXr169XS0uLpk2bprq6uvZ9Hn30Ub399tt68803VVFRocrKSs2aNSvuCwcAdG9Ob0JYt25dh49Xrlyp7Oxs7dixQ1OmTFE0GtVf//pXrVq1SrfeeqskacWKFbr66qu1detW59+qBwDoub7Ta0DRaFTS/94xs2PHDrW0tKi4uLh9n9GjR2vw4MHasmXLOf+OpqYmxWKxDhsAoOfzLqC2tjYtXLhQkydP1pgxYyRJVVVVSklJUf/+/Tvsm5OTo6qqqnP+PWVlZYpEIu1bQUGB75IAAN2IdwGVlpZqz549eu21177TAhYvXqxoNNq++fy8DACg+/H6QdQFCxbonXfe0aZNmzRo0KD2x3Nzc9Xc3KyampoOd0HV1dXKzc09598VDocVDod9lgEA6Mac7oCCINCCBQu0evVqbdiwQcOGDevw/IQJE9S7d2+Vl5e3P7Z3714dOnRIRUVF8VkxAKBHcLoDKi0t1apVq7R27Vqlp6e3v64TiUSUmpqqSCSi+++/X4sWLVJmZqYyMjL0yCOPqKioiHfAAQA6cCqg5cuXS5JuvvnmDo+vWLFC8+bNkyT9/ve/V1JSkmbPnq2mpiZNnz5df/rTn+KyWABAzxEKgiCwXsQ3xWIxRSIRjR07VsnJyZec+/Of/+x8rBMnTjhnJKlfv37OmQEDBjhnfAY1njp1yjnjMzxRknr1cn8J0WfoYt++fZ0zPgNMJb9zkZTk/l4en0+7b7+79FJ884fEXfgMc/3qq6+cMz6v//p83voMMJX8hpj6HCs1NdU5c77X1S/GZ4jpK6+84rR/U1OT/vjHPyoajV5w2DGz4AAAJiggAIAJCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJrx+I2pn+OSTT5z2f+utt5yP8ZOf/MQ5I0mVlZXOmc8++8w509jY6JzxmQLtOw3bZ4JvSkqKc8ZlKvrXmpqanDOS1Nra6pzxmWxdX1/vnDl69KhzxnfYvc958JmO3lnXeHNzs3NG8ptI75PxmaDtM6lb0lm/SPRSVFdXO+1/qeebOyAAgAkKCABgggICAJiggAAAJiggAIAJCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAmQoHvtMIEicViikQinXKskpISr9xjjz3mnMnOznbOnDhxwjnjMwjRZ/Ck5Dck1GcYqc+QS5+1SVIoFHLO+HwK+QyA9cn4nG/fY/mcOx8+x3Edpvld+JzztrY250xubq5zRpJ2797tnLnrrru8jhWNRpWRkXHe57kDAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJiggAIAJCggAYKLLDiMNhUJOQwd9hvl1pltuucU5U1ZW5pzxGXrqO/w1Kcn9/198hoT6DCP1HbDq49ixY84Zn0+7L7/80jnj+3lx6tQp54zvAFhXPueupaXF61j19fXOGZ/Pi/Xr1ztnPv30U+eMJG3evNkr54NhpACALokCAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJiggAICJLjuMFJ1n9OjRXrmsrCznTE1NjXNm0KBBzpnPP//cOSP5Da08cOCA17GAno5hpACALokCAgCYcCqgsrIyTZw4Uenp6crOztbMmTO1d+/eDvvcfPPN7b/L5+vt4YcfjuuiAQDdn1MBVVRUqLS0VFu3btX69evV0tKiadOmqa6ursN+Dz74oI4ePdq+LV26NK6LBgB0f06/anLdunUdPl65cqWys7O1Y8cOTZkypf3xvn37Kjc3Nz4rBAD0SN/pNaBoNCpJyszM7PD4K6+8oqysLI0ZM0aLFy++4K+1bWpqUiwW67ABAHo+pzugb2pra9PChQs1efJkjRkzpv3xe++9V0OGDFF+fr52796tJ554Qnv37tVbb711zr+nrKxMzz77rO8yAADdlPfPAc2fP1/vvfeePvzwwwv+nMaGDRs0depU7d+/XyNGjDjr+aamJjU1NbV/HIvFVFBQ4LMkeOLngP6HnwMC4udiPwfkdQe0YMECvfPOO9q0adNFvzgUFhZK0nkLKBwOKxwO+ywDANCNORVQEAR65JFHtHr1am3cuFHDhg27aGbXrl2SpLy8PK8FAgB6JqcCKi0t1apVq7R27Vqlp6erqqpKkhSJRJSamqoDBw5o1apV+uEPf6gBAwZo9+7devTRRzVlyhSNGzcuIf8BAIDuyamAli9fLunMD5t+04oVKzRv3jylpKTo/fff1wsvvKC6ujoVFBRo9uzZevLJJ+O2YABAz+D8LbgLKSgoUEVFxXdaEADg8sA0bABAQjANGwDQJVFAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMAEBQQAMEEBAQBMUEAAABMUEADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMAEBQQAMEEBAQBMUEAAABMUEADABAUEADDR5QooCALrJQAA4uBiX8+7XAHV1tZaLwEAEAcX+3oeCrrYLUdbW5sqKyuVnp6uUCjU4blYLKaCggIdPnxYGRkZRiu0x3k4g/NwBufhDM7DGV3hPARBoNraWuXn5ysp6fz3Ob06cU2XJCkpSYMGDbrgPhkZGZf1BfY1zsMZnIczOA9ncB7OsD4PkUjkovt0uW/BAQAuDxQQAMBEtyqgcDisJUuWKBwOWy/FFOfhDM7DGZyHMzgPZ3Sn89Dl3oQAALg8dKs7IABAz0EBAQBMUEAAABMUEADARLcpoGXLlmno0KHq06ePCgsL9dFHH1kvqdM988wzCoVCHbbRo0dbLyvhNm3apNtvv135+fkKhUJas2ZNh+eDINDTTz+tvLw8paamqri4WPv27bNZbAJd7DzMmzfvrOtjxowZNotNkLKyMk2cOFHp6enKzs7WzJkztXfv3g77NDY2qrS0VAMGDFBaWppmz56t6upqoxUnxqWch5tvvvms6+Hhhx82WvG5dYsCev3117Vo0SItWbJEH3/8scaPH6/p06fr2LFj1kvrdNdcc42OHj3avn344YfWS0q4uro6jR8/XsuWLTvn80uXLtWLL76ol156Sdu2bVO/fv00ffp0NTY2dvJKE+ti50GSZsyY0eH6ePXVVztxhYlXUVGh0tJSbd26VevXr1dLS4umTZumurq69n0effRRvf3223rzzTdVUVGhyspKzZo1y3DV8Xcp50GSHnzwwQ7Xw9KlS41WfB5BNzBp0qSgtLS0/ePW1tYgPz8/KCsrM1xV51uyZEkwfvx462WYkhSsXr26/eO2trYgNzc3+O1vf9v+WE1NTRAOh4NXX33VYIWd49vnIQiCYO7cucEdd9xhsh4rx44dCyQFFRUVQRCc+bfv3bt38Oabb7bv8+mnnwaSgi1btlgtM+G+fR6CIAj+7//+L/jZz35mt6hL0OXvgJqbm7Vjxw4VFxe3P5aUlKTi4mJt2bLFcGU29u3bp/z8fA0fPlz33XefDh06ZL0kUwcPHlRVVVWH6yMSiaiwsPCyvD42btyo7OxsXXXVVZo/f75OnjxpvaSEikajkqTMzExJ0o4dO9TS0tLhehg9erQGDx7co6+Hb5+Hr73yyivKysrSmDFjtHjxYtXX11ss77y63DDSbztx4oRaW1uVk5PT4fGcnBz95z//MVqVjcLCQq1cuVJXXXWVjh49qmeffVY33XST9uzZo/T0dOvlmaiqqpKkc14fXz93uZgxY4ZmzZqlYcOG6cCBA/rlL3+pkpISbdmyRcnJydbLi7u2tjYtXLhQkydP1pgxYySduR5SUlLUv3//Dvv25OvhXOdBku69914NGTJE+fn52r17t5544gnt3btXb731luFqO+ryBYT/KSkpaf/zuHHjVFhYqCFDhuiNN97Q/fffb7gydAV33313+5/Hjh2rcePGacSIEdq4caOmTp1quLLEKC0t1Z49ey6L10Ev5Hzn4aGHHmr/89ixY5WXl6epU6fqwIEDGjFiRGcv85y6/LfgsrKylJycfNa7WKqrq5Wbm2u0qq6hf//+GjVqlPbv32+9FDNfXwNcH2cbPny4srKyeuT1sWDBAr3zzjv64IMPOvz6ltzcXDU3N6umpqbD/j31ejjfeTiXwsJCSepS10OXL6CUlBRNmDBB5eXl7Y+1tbWpvLxcRUVFhiuzd+rUKR04cEB5eXnWSzEzbNgw5ebmdrg+YrGYtm3bdtlfH0eOHNHJkyd71PURBIEWLFig1atXa8OGDRo2bFiH5ydMmKDevXt3uB727t2rQ4cO9ajr4WLn4Vx27dolSV3rerB+F8SleO2114JwOBysXLky+Pe//x089NBDQf/+/YOqqirrpXWqn//858HGjRuDgwcPBv/85z+D4uLiICsrKzh27Jj10hKqtrY22LlzZ7Bz585AUvC73/0u2LlzZ/DFF18EQRAEzz//fNC/f/9g7dq1we7du4M77rgjGDZsWNDQ0GC88vi60Hmora0NHnvssWDLli3BwYMHg/fffz/4wQ9+EIwcOTJobGy0XnrczJ8/P4hEIsHGjRuDo0ePtm/19fXt+zz88MPB4MGDgw0bNgTbt28PioqKgqKiIsNVx9/FzsP+/fuDX/3qV8H27duDgwcPBmvXrg2GDx8eTJkyxXjlHXWLAgqCIPjDH/4QDB48OEhJSQkmTZoUbN261XpJnW7OnDlBXl5ekJKSElxxxRXBnDlzgv3791svK+E++OCDQNJZ29y5c4MgOPNW7KeeeirIyckJwuFwMHXq1GDv3r22i06AC52H+vr6YNq0acHAgQOD3r17B0OGDAkefPDBHvc/aef675cUrFixon2fhoaG4Kc//Wnwve99L+jbt29w5513BkePHrVbdAJc7DwcOnQomDJlSpCZmRmEw+HgyiuvDH7xi18E0WjUduHfwq9jAACY6PKvAQEAeiYKCABgggICAJiggAAAJiggAIAJCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAm/h+r5MpJjoz0fwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import numpy as np\n",
        "np.set_printoptions(linewidth=200)\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(training_images[0], cmap=\"gray\") # recordad que siempre es preferible trabajar en blanco y negro\n",
        "#\n",
        "print(training_labels[0])\n",
        "print(training_images[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCJvZx3MLucY"
      },
      "source": [
        "Habréis notado que todos los valores numericos están entre 0 y 255. Si estamos entrenando una red neuronal, una buena practica es transformar todos los valores entre 0 y 1, un proceso llamado \"normalización\" y afortunadamente en Python es fácil normalizar una lista. Lo puedes hacer de esta manera:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tojL1BmjG4h_"
      },
      "outputs": [],
      "source": [
        "training_images  = training_images / 255.0\n",
        "test_images = test_images / 255.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaqXlSMBwmMg"
      },
      "source": [
        "## 1. Información sobre el dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0aer8ZZwmMh"
      },
      "source": [
        "Una vez tenemos los datos cargados en memoria, vamos a obtener información sobre los mismos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-im9PnEwmMh"
      },
      "source": [
        "**Pregunta 1.1 *(0.25 puntos)*** ¿Cuántas imágenes hay de *training* y de *test*? ¿Qué tamaño tienen las imágenes?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lvP0Y4SCwmMi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffa0d478-6fdf-49e1-963d-60e88be5777d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de imágenes en el conjunto de entrenamiento:  60000\n",
            "Cantidad de imágenes en el conjunto de prueba:  10000\n",
            "Tamaño de las imágenes:  (28, 28)\n"
          ]
        }
      ],
      "source": [
        "### Tu código aquí ###\n",
        "# Creamos variables\n",
        "num_train_images = training_images.shape[0]\n",
        "num_test_images = test_images.shape[0]\n",
        "\n",
        "# Obtenemos el tamaño de las imágenes\n",
        "image_size = training_images.shape[1:]\n",
        "\n",
        "# Imprimimos la información obtenida\n",
        "print(\"Cantidad de imágenes en el conjunto de entrenamiento: \", num_train_images)\n",
        "print(\"Cantidad de imágenes en el conjunto de prueba: \", num_test_images)\n",
        "print(\"Tamaño de las imágenes: \", image_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xwp5ljFKwmMj"
      },
      "source": [
        "Hay 60.000 imágenes en el dataset de entrenamiento, 10.000 en el de test. Las imágenes tienen un tamaño de 28x28."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2LsvfHOwmMk"
      },
      "source": [
        "**Pregunta 1.2 *(0.25 puntos)*** Realizar una exploración de las variables que contienen los datos. Describir en qué consiste un example del dataset (qué información se guarda en cada imagen) y describir qué contiene la información en y."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3W5rzaGxwmMk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6aa311cf-577d-4d5f-eb66-3e0dd354579c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamaño del conjunto de entrenamiento (imágenes): (60000, 28, 28)\n",
            "Tamaño del conjunto de prueba (imágenes): (10000, 28, 28)\n",
            "Tamaño del conjunto de entrenamiento (etiquetas): (60000,)\n",
            "Tamaño del conjunto de prueba (etiquetas): (10000,)\n",
            "Tipo de datos de las imágenes: float64\n",
            "Tipo de datos de las etiquetas: uint8\n",
            "Valores únicos en las etiquetas: [0 1 2 3 4 5 6 7 8 9]\n",
            "Cantidad de clases: 10\n"
          ]
        }
      ],
      "source": [
        "### Tu código aquí ###\n",
        "# Exploración de las variables\n",
        "print(\"Tamaño del conjunto de entrenamiento (imágenes):\", training_images.shape)\n",
        "print(\"Tamaño del conjunto de prueba (imágenes):\", test_images.shape)\n",
        "print(\"Tamaño del conjunto de entrenamiento (etiquetas):\", training_labels.shape)\n",
        "print(\"Tamaño del conjunto de prueba (etiquetas):\", test_labels.shape)\n",
        "print(\"Tipo de datos de las imágenes:\", training_images.dtype)\n",
        "print(\"Tipo de datos de las etiquetas:\", training_labels.dtype)\n",
        "print(\"Valores únicos en las etiquetas:\", np.unique(training_labels))\n",
        "print(\"Cantidad de clases:\", len(np.unique(training_labels)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zaEWKFyvwmMm"
      },
      "source": [
        "Se muestra el tamaño de los conjuntos de entrenamiento y prueba, así como el tipo de datos de las imágenes y las etiquetas. Además, se muestra la cantidad de valores únicos en las etiquetas, que corresponde al número de clases en el conjunto de datos MNIST, que en este caso son los dígitos del 0 al 9, correspondientes a 10 tipos diferentes de ropa."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir las etiquetas correspondientes a cada clase\n",
        "class_names = {\n",
        "    0: \"Camiseta/top\",\n",
        "    1: \"Pantalón\",\n",
        "    2: \"Suéter\",\n",
        "    3: \"Vestido\",\n",
        "    4: \"Abrigo\",\n",
        "    5: \"Sandalia\",\n",
        "    6: \"Camisa\",\n",
        "    7: \"Zapatilla de deporte\",\n",
        "    8: \"Bolso\",\n",
        "    9: \"Botín\"\n",
        "}\n",
        "\n",
        "# Mostrar la cantidad de datos de entrenamiento y prueba para cada clase\n",
        "import pandas as pd\n",
        "data = []\n",
        "for label, class_name in class_names.items():\n",
        "    train_count = np.sum(training_labels == label)\n",
        "    test_count = np.sum(test_labels == label)\n",
        "    data.append([label, class_name, train_count, test_count])\n",
        "\n",
        "df = pd.DataFrame(data, columns=['Clase', 'Nombre de Clase', 'Entrenamiento', 'Prueba'])\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvqTA8MrK-VC",
        "outputId": "daa15f05-29c3-4ffb-bba1-bed69af86192"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Clase       Nombre de Clase  Entrenamiento  Prueba\n",
            "0      0          Camiseta/top           6000    1000\n",
            "1      1              Pantalón           6000    1000\n",
            "2      2                Suéter           6000    1000\n",
            "3      3               Vestido           6000    1000\n",
            "4      4                Abrigo           6000    1000\n",
            "5      5              Sandalia           6000    1000\n",
            "6      6                Camisa           6000    1000\n",
            "7      7  Zapatilla de deporte           6000    1000\n",
            "8      8                 Bolso           6000    1000\n",
            "9      9                 Botín           6000    1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hay 6.000 imágenes de cada tipo en el dataset de entrenamiento (60.000 en total) y 1.000 en el de prueba (10.000 en total)."
      ],
      "metadata": {
        "id": "d4MDBVubLMNz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def show_images(training_images,\n",
        "            \tclass_names,\n",
        "            \ttrain_labels,\n",
        "            \tnb_samples = 12, nb_row = 4):\n",
        "    \n",
        "\tplt.figure(figsize=(12, 12))\n",
        "\tfor i in range(nb_samples):\n",
        "    \tplt.subplot(nb_row, nb_row, i + 1)\n",
        "    \tplt.xticks([])\n",
        "    \tplt.yticks([])\n",
        "    \tplt.grid(False)\n",
        "    \tplt.imshow(training_images[i], cmap=plt.cm.binary)\n",
        "    \tplt.xlabel(class_names[training_labels[i][0]])\n",
        "\tplt.show()\n",
        " class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "           \t'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "show_images(train_images, class_names, train_labels)"
      ],
      "metadata": {
        "id": "F6Kv5a2TiOnc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dI3IAhOQ8zHi"
      },
      "source": [
        "## 2. Creación del Modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYUWWsszMAKt"
      },
      "source": [
        "Ahora vamos a definir el modelo, pero antes vamos a repasar algunos comandos y conceptos muy útiles:\n",
        "* **Sequential**: Eso define una SECUENCIA de capas en la red neuronal\n",
        "* **Dense**: Añade una capa de neuronas\n",
        "* **Flatten**: ¿Recuerdas cómo eran las imágenes cuando las imprimiste para poder verlas? Un cuadrado, Flatten toma ese cuadrado y lo convierte en un vector de una dimensión.\n",
        "\n",
        "Cada capa de neuronas necesita una función de activación. Normalmente se usa la función relu en las capas intermedias y softmax en la ultima capa (en problemas de clasificación de más de dos items)\n",
        "* **Relu** significa que \"Si X>0 devuelve X, si no, devuelve 0\", así que lo que hace es pasar sólo valores 0 o mayores a la siguiente capa de la red.\n",
        "* **Softmax** toma un conjunto de valores, y escoge el más grande."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgBW1yE2MwPp"
      },
      "source": [
        " **Pregunta 2.1 (2 puntos)**. Utilizando Keras, y preparando los datos de X e y como fuera necesario, define y entrena una red neuronal que sea capaz de clasificar imágenes de Fashion MNIST con las siguientes características:\n",
        "\n",
        "* Una hidden layer de tamaños 128, utilizando unidades sigmoid\n",
        "Optimizador Adam.\n",
        "* Durante el entrenamiento, la red tiene que mostrar resultados de loss y accuracy por cada epoch.\n",
        "* La red debe entrenar durante 10 epochs y batch size de 64.\n",
        "* La última capa debe de ser una capa softmax.\n",
        "* Tu red tendría que ser capaz de superar fácilmente 80% de accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aTaD2QXIORwu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9b78c32-de35-4f19-9073-edc6210f594f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_10 (Dense)            (None, 128)               100480    \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 101,770\n",
            "Trainable params: 101,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 0.5965 - accuracy: 0.8025 - val_loss: 0.4663 - val_accuracy: 0.8358\n",
            "Epoch 2/10\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 0.4126 - accuracy: 0.8530 - val_loss: 0.4174 - val_accuracy: 0.8514\n",
            "Epoch 3/10\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.3742 - accuracy: 0.8667 - val_loss: 0.3987 - val_accuracy: 0.8555\n",
            "Epoch 4/10\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.3486 - accuracy: 0.8741 - val_loss: 0.3903 - val_accuracy: 0.8621\n",
            "Epoch 5/10\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.3298 - accuracy: 0.8811 - val_loss: 0.3849 - val_accuracy: 0.8597\n",
            "Epoch 6/10\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.3149 - accuracy: 0.8861 - val_loss: 0.3781 - val_accuracy: 0.8654\n",
            "Epoch 7/10\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.3018 - accuracy: 0.8904 - val_loss: 0.3554 - val_accuracy: 0.8692\n",
            "Epoch 8/10\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.2914 - accuracy: 0.8938 - val_loss: 0.3583 - val_accuracy: 0.8689\n",
            "Epoch 9/10\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.2790 - accuracy: 0.8986 - val_loss: 0.3422 - val_accuracy: 0.8780\n",
            "Epoch 10/10\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.2716 - accuracy: 0.8998 - val_loss: 0.3387 - val_accuracy: 0.8800\n"
          ]
        }
      ],
      "source": [
        "### Tu código para la red neuronal de la pregunta 2 aquí ###\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Cargar el conjunto de datos Fashion MNIST\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Preprocesamiento de los datos\n",
        "num_classes = 10\n",
        "input_shape = (784,)  # 28x28 = 784\n",
        "\n",
        "# Aplanar las imágenes y convertir las etiquetas a one-hot encoding\n",
        "training_images = training_images.reshape(-1, 784).astype('float32') / 255.0\n",
        "test_images = test_images.reshape(-1, 784).astype('float32') / 255.0\n",
        "training_labels = to_categorical(training_labels, num_classes)\n",
        "test_labels = to_categorical(test_labels, num_classes)\n",
        "\n",
        "# Definir la arquitectura de la red neuronal\n",
        "model = Sequential()\n",
        "model.add(Dense(128, activation='sigmoid', input_shape=input_shape))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Compilar el modelo\n",
        "optimizer = Adam()\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Mostrar la información del modelo\n",
        "model.summary()\n",
        "\n",
        "# Entrenar el modelo\n",
        "batch_size = 64\n",
        "epochs = 10\n",
        "history = model.fit(training_images, training_labels, batch_size=batch_size, epochs=epochs,\n",
        "                    verbose=1, validation_data=(test_images, test_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este código define una red neuronal con una capa oculta (hidden layer) de tamaño 128 con función de activación sigmoid, y una capa de salida con función de activación softmax para la clasificación multiclase. Utiliza el optimizador Adam para la optimización del modelo. Durante el entrenamiento, se muestra la pérdida (loss) y la precisión (accuracy) en cada epoch. El modelo se entrena durante 10 epochs con un batch size de 64, y luego se evalúa en el conjunto de prueba. El modelo supera el 80% de accuracy en el conjunto de prueba en todas las iteraciones, alcanzando casi el 90% en la última."
      ],
      "metadata": {
        "id": "jq-jCpMlMii2"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bxr5hTKYOQnK"
      },
      "source": [
        "Para concluir el entrenamiento de la red neuronal, una buena práctica es evaluar el modelo para ver si la precisión de entrenamiento es real\n",
        "\n",
        "**pregunta 2.2 (0.5 puntos)**: Evalúa el modelo con las imágenes y etiquetas test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VNjQEtUUG4iI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f6faf08-a4dc-4009-9496-249ed969c121"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pérdida en el conjunto de prueba: 0.337945818901062\n",
            "Precisión en el conjunto de prueba: 0.8791999816894531\n"
          ]
        }
      ],
      "source": [
        "### Tu código para la evaluación de la red neuronal de la pregunta 2 aquí ###\n",
        "# Evaluar el modelo en el conjunto de prueba\n",
        "test_loss, test_accuracy = model.evaluate(test_images, test_labels, verbose=0)\n",
        "print('Pérdida en el conjunto de prueba:', test_loss)\n",
        "print('Precisión en el conjunto de prueba:', test_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygMVnmSYO83U"
      },
      "source": [
        "\n",
        "## 3: Funcionamiento de las predicción de la red neuronal\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMa-GR0Kvcqh"
      },
      "source": [
        "Ahora vamos a explorar el código con una serie de ejercicios para alcanzar un grado de comprensión mayor sobre las redes neuronales y su entrenamiento.\n",
        "\n",
        "Sigue los siguientes pasos: \n",
        "\n",
        "* Crea una variable llamada **classifications** para construir un clasificador con las imágenes de prueba, para ello puedes utilizar la función predict sobre el conjunto de test\n",
        "* Imprime con la función print la primera entrada en las clasificaciones. \n",
        "\n",
        "**pregunta 3.1 (0.25 puntos)**, el resultado al imprimirlo es un vector de números, \n",
        "* ¿Por qué crees que ocurre esto? ¿Qué representa este vector de números?\n",
        "\n",
        "**pregunta 3.2 (0.25 puntos)**\n",
        "* ¿Cúal es la clase de la primera entrada de la variable **classifications**? La respuesta puede ser un número o su etiqueta/clase equivalente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b-mL-h4xQhCm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2ca70e4-b9e2-4eef-a309-af01a2729c6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 2s 6ms/step\n",
            "Clasificación de la primera imagen en el conjunto de prueba: [3.1458796e-06 4.3785835e-07 1.1750638e-05 1.4547151e-05 8.0252303e-06 3.2272249e-02 3.0358329e-05 3.4877427e-02 4.9514486e-04 9.3228692e-01]\n"
          ]
        }
      ],
      "source": [
        "### Tu código del clasificador de la pregunta 3 aquí ###\n",
        "# Obtener las clasificaciones de las imágenes de prueba\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "# Imprimir la primera entrada en las clasificaciones\n",
        "print('Clasificación de la primera imagen en el conjunto de prueba:', classifications[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Respuesta a la pregunta 3.1**"
      ],
      "metadata": {
        "id": "rSGQLi2VOhsJ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvbVC9gaQhMY"
      },
      "source": [
        "El vector de números que se obtiene al imprimir la primera entrada en las clasificaciones es un vector de probabilidades. Cada valor en el vector representa la probabilidad de que la imagen correspondiente en el conjunto de prueba pertenezca a una determinada clase de Fashion MNIST. La razón por la que se obtiene un vector de probabilidades en lugar de una etiqueta única es porque se utilizó una función de activación softmax en la capa de salida del modelo. La función softmax convierte las salidas de la red neuronal en una distribución de probabilidad, donde la suma de todas las probabilidades es igual a 1. Cada valor en el vector de probabilidades representa la probabilidad de que la imagen sea clasificada en una clase específica.\n",
        "El vector de números que se obtiene al imprimir la primera entrada en las clasificaciones es un vector de probabilidades. Cada valor en el vector representa la probabilidad de que la imagen correspondiente en el conjunto de prueba pertenezca a una determinada clase de Fashion MNIST. La razón por la que se obtiene un vector de probabilidades en lugar de una etiqueta única es porque se utilizó una función de activación softmax en la capa de salida del modelo. La función softmax convierte las salidas de la red neuronal en una distribución de probabilidad, donde la suma de todas las probabilidades es igual a 1. Cada valor en el vector de probabilidades representa la probabilidad de que la imagen sea clasificada en una clase específica."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRWo-75tdgv0"
      },
      "source": [
        "**Respuesta a la pregunta 3.2**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Obtener el índice con la probabilidad más alta en el vector de probabilidades\n",
        "pred_class_index = np.argmax(classifications[0])\n",
        "\n",
        "# Obtener la etiqueta/clase equivalente al índice\n",
        "pred_class = class_names[pred_class_index]\n",
        "\n",
        "# Imprimir la clase predicha\n",
        "print('Clase predicha para la primera imagen en el conjunto de prueba:', pred_class)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-L9ErNTZORNm",
        "outputId": "87a84866-b358-45c5-ea1c-0782d1a88e31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clase predicha para la primera imagen en el conjunto de prueba: Botín\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para obtener la etiqueta de clasificación única, se puede utilizar la función argmax() de NumPy para encontrar el índice con la probabilidad más alta en el vector de probabilidades. Ese índice corresponderá a la clase predicha para la imagen. La clase de la primera entrada en la variable classifications corresponde a la clase predicha para la primera imagen en el conjunto de prueba de Fashion MNIST. Esta clase se puede obtener utilizando la función argmax() de NumPy, que devuelve el índice con el valor más alto en un vector de números. En este código, class_names es una lista que contiene las etiquetas/clases equivalentes a los valores numéricos en Fashion MNIST, que van del 0 al 9. La variable pred_class contendrá la etiqueta/clase equivalente a la clase predicha para la primera imagen en el conjunto de prueba."
      ],
      "metadata": {
        "id": "R_dasfY-Om0_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiQ8qAzhRQ4L"
      },
      "source": [
        "## 4: Impacto variar el número de neuronas en las capas ocultas\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lsqive4ivMF9"
      },
      "source": [
        "En este ejercicio vamos a experimentar con nuestra red neuronal cambiando el numero de neuronas por 512 y por 1024. Para ello, utiliza la red neuronal de la pregunta 1, y en su capa oculta cambia las 128 neuronas por:\n",
        "\n",
        "* **512 neuronas en la capa oculta\n",
        "* **1024 neuronas en la capa oculta\n",
        "\n",
        "Entrena la red en ambos casos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cdP8ZwuaUV93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f8754ff-ad03-444c-efc9-224db2f859f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_4 (Dense)             (None, 512)               401920    \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 407,050\n",
            "Trainable params: 407,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "938/938 [==============================] - 12s 12ms/step - loss: 0.5294 - accuracy: 0.8133 - val_loss: 0.4546 - val_accuracy: 0.8342\n",
            "Epoch 2/10\n",
            "938/938 [==============================] - 11s 11ms/step - loss: 0.4032 - accuracy: 0.8539 - val_loss: 0.4242 - val_accuracy: 0.8480\n",
            "Epoch 3/10\n",
            "938/938 [==============================] - 11s 11ms/step - loss: 0.3634 - accuracy: 0.8683 - val_loss: 0.3887 - val_accuracy: 0.8589\n",
            "Epoch 4/10\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.3374 - accuracy: 0.8771 - val_loss: 0.3902 - val_accuracy: 0.8570\n",
            "Epoch 5/10\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.3164 - accuracy: 0.8845 - val_loss: 0.3842 - val_accuracy: 0.8624\n",
            "Epoch 6/10\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 0.2992 - accuracy: 0.8895 - val_loss: 0.3633 - val_accuracy: 0.8712\n",
            "Epoch 7/10\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.2821 - accuracy: 0.8953 - val_loss: 0.3407 - val_accuracy: 0.8768\n",
            "Epoch 8/10\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.2682 - accuracy: 0.9011 - val_loss: 0.3300 - val_accuracy: 0.8799\n",
            "Epoch 9/10\n",
            "938/938 [==============================] - 11s 11ms/step - loss: 0.2585 - accuracy: 0.9050 - val_loss: 0.3344 - val_accuracy: 0.8796\n",
            "Epoch 10/10\n",
            "938/938 [==============================] - 17s 19ms/step - loss: 0.2450 - accuracy: 0.9080 - val_loss: 0.3321 - val_accuracy: 0.8819\n"
          ]
        }
      ],
      "source": [
        "### Tu código para 512 neuronas aquí ###\n",
        "# Definimos la arquitectura de la red neuronal\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='sigmoid', input_shape=input_shape))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Compilamos el modelo\n",
        "optimizer = Adam()\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Mostramos la información del modelo\n",
        "model.summary()\n",
        "\n",
        "# Entrenamos el modelo\n",
        "batch_size = 64\n",
        "epochs = 10\n",
        "history = model.fit(training_images, training_labels, batch_size=batch_size, epochs=epochs,\n",
        "                    verbose=1, validation_data=(test_images, test_labels))\n",
        "\n",
        "# Evaluación del modelo en el conjunto de prueba\n",
        "test_loss, test_accuracy = model.evaluate(test_images, test_labels, verbose=0)\n",
        "print('Pérdida en el conjunto de prueba:', test_loss)\n",
        "print('Precisión en el conjunto de prueba:', test_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YXBlbbfuUaPa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4815b1b4-ef47-4359-8e7b-41e6c2583812"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_8 (Dense)             (None, 1024)              803840    \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 10)                10250     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 814,090\n",
            "Trainable params: 814,090\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "938/938 [==============================] - 21s 20ms/step - loss: 0.5271 - accuracy: 0.8120 - val_loss: 0.4512 - val_accuracy: 0.8360\n",
            "Epoch 2/10\n",
            "938/938 [==============================] - 20s 21ms/step - loss: 0.4011 - accuracy: 0.8562 - val_loss: 0.4185 - val_accuracy: 0.8491\n",
            "Epoch 3/10\n",
            "938/938 [==============================] - 20s 21ms/step - loss: 0.3674 - accuracy: 0.8651 - val_loss: 0.4308 - val_accuracy: 0.8450\n",
            "Epoch 4/10\n",
            "938/938 [==============================] - 21s 23ms/step - loss: 0.3384 - accuracy: 0.8756 - val_loss: 0.3657 - val_accuracy: 0.8665\n",
            "Epoch 5/10\n",
            "938/938 [==============================] - 19s 20ms/step - loss: 0.3142 - accuracy: 0.8845 - val_loss: 0.3655 - val_accuracy: 0.8686\n",
            "Epoch 6/10\n",
            "938/938 [==============================] - 19s 21ms/step - loss: 0.2930 - accuracy: 0.8921 - val_loss: 0.3517 - val_accuracy: 0.8740\n",
            "Epoch 7/10\n",
            "938/938 [==============================] - 21s 22ms/step - loss: 0.2777 - accuracy: 0.8972 - val_loss: 0.3360 - val_accuracy: 0.8777\n",
            "Epoch 8/10\n",
            "938/938 [==============================] - 20s 22ms/step - loss: 0.2641 - accuracy: 0.9004 - val_loss: 0.3344 - val_accuracy: 0.8798\n",
            "Epoch 9/10\n",
            "938/938 [==============================] - 19s 20ms/step - loss: 0.2494 - accuracy: 0.9060 - val_loss: 0.3279 - val_accuracy: 0.8801\n",
            "Epoch 10/10\n",
            "938/938 [==============================] - 21s 22ms/step - loss: 0.2370 - accuracy: 0.9103 - val_loss: 0.3361 - val_accuracy: 0.8841\n",
            "Pérdida en el conjunto de prueba: 0.33614563941955566\n",
            "Precisión en el conjunto de prueba: 0.8841000199317932\n"
          ]
        }
      ],
      "source": [
        "### Tu código para 1024 neuronas aquí ###\n",
        "# Definimos la arquitectura de la red neuronal\n",
        "model = Sequential()\n",
        "model.add(Dense(1024, activation='sigmoid', input_shape=input_shape))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Compilamos el modelo\n",
        "optimizer = Adam()\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Mostramos la información del modelo\n",
        "model.summary()\n",
        "\n",
        "# Entrenamos el modelo\n",
        "batch_size = 64\n",
        "epochs = 10\n",
        "history = model.fit(training_images, training_labels, batch_size=batch_size, epochs=epochs,\n",
        "                    verbose=1, validation_data=(test_images, test_labels))\n",
        "\n",
        "# Evaluación del modelo en el conjunto de prueba\n",
        "test_loss, test_accuracy = model.evaluate(test_images, test_labels, verbose=0)\n",
        "print('Pérdida en el conjunto de prueba:', test_loss)\n",
        "print('Precisión en el conjunto de prueba:', test_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wG0h2HL-Uj93"
      },
      "source": [
        "**pregunta 4.1 (0.5 puntos)**: ¿Cuál es el impacto que tiene la red neuronal? "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AkZYq4xBvnrS"
      },
      "outputs": [],
      "source": [
        "#Tu respuesta a la pregunta 4.1 aquí:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-NpUI9EVkVz"
      },
      "source": [
        "Si ahora entrenais el modelo de esta forma (con 512 y 1024 neuronas en la capa oculta) y volveis a ejecutar el predictor guardado en la variable **classifications**, escribir el código del clasificador del ejercicio 1 de nuevo e imprimid el primer objeto guardado en la variable classifications.\n",
        "\n",
        "**pregunta 4.2 (0.25 puntos)**: \n",
        "\n",
        "* ¿En qué clase está clasificado ahora la primera prenda de vestir de la variable classifications?\n",
        "\n",
        "**pregunta 4.3 (0.25 puntos)**: \n",
        "\n",
        "* ¿Por qué crees que ha ocurrido esto?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RdJHl3V-G4iS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcf7232e-232c-414f-f992-d68d5d022d30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 2s 5ms/step\n",
            "Clase predicha para la primera imagen en el conjunto de prueba: Botín\n"
          ]
        }
      ],
      "source": [
        "### Tu código del clasificador de la pregunta 4 aquí ###\n",
        "# Obtener el índice con la probabilidad más alta en el vector de probabilidades\n",
        "pred = model.predict(test_images)\n",
        "class_idx = np.argmax(pred[0])\n",
        "\n",
        "# Obtener la etiqueta/clase equivalente al índice\n",
        "pred_class = class_names[class_idx]\n",
        "\n",
        "# Imprimir la clase predicha\n",
        "print('Clase predicha para la primera imagen en el conjunto de prueba:', pred_class)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3NfwdOGZcAa"
      },
      "source": [
        "Tu respuesta a la pregunta 4.2 aquí:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFmfpxE1ZcJx"
      },
      "source": [
        "**Respuesta a la pregunta 4.3:**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Tamaño del modelo: Es posible que el tamaño del modelo sea demasiado grande en comparación con la complejidad del problema. Si el modelo es demasiado complejo, puede aprender a ajustarse en exceso a los datos de entrenamiento y clasificar todas las imágenes en la misma clase sin generalizar bien a nuevas imágenes.\n",
        "*   Funciones de activación: La elección de la función de activación en las capas de la red neuronal también puede tener un impacto en la capacidad del modelo para aprender representaciones adecuadas de los datos. Algunas funciones de activación, como la función sigmoide, pueden tener problemas de saturación en ciertos rangos de valores, lo que puede resultar en una pérdida de información y afectar la capacidad del modelo para discriminar entre diferentes clases.\n",
        "*   Otros hiperparámetros: Además del tamaño del modelo y las funciones de activación, otros hiperparámetros, como la tasa de aprendizaje, el número de epochs, el tamaño del lote (batch size), entre otros, también pueden afectar el rendimiento del modelo. Es posible que sea necesario ajustar estos hiperparámetros para obtener un mejor rendimiento en la clasificación de imágenes."
      ],
      "metadata": {
        "id": "N8CXKX2qTy6L"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59eM76O1YekZ"
      },
      "source": [
        "## 5: Capa Flatten\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6LGnSxBu-ww"
      },
      "source": [
        "En este ejercicio vamos a ver que ocurre cuando quitamos la capa flatten, para ello, escribe la red neuronal de la pregunta 1 y no pongas la capa Flatten.\n",
        "\n",
        "**pregunta 5 (0.5 puntos):** ¿Puedes explicar a qué se debe el error que da?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ecfEVKEuG4iU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 971
        },
        "outputId": "ada54845-cef5-4a3c-9748-80fd5a7bc20c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_14 (Dense)            (None, 128)               100480    \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 101,770\n",
            "Trainable params: 101,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-9653c5c0136e>\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m history = model.fit(training_images, training_labels, batch_size=batch_size, epochs=epochs,\n\u001b[0m\u001b[1;32m     25\u001b[0m                     verbose=1, validation_data=(test_images, test_labels))\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_7\" is incompatible with the layer: expected shape=(None, 784), found shape=(None, 28, 28)\n"
          ]
        }
      ],
      "source": [
        "### Tu código de la red neuronal sin capa flatten de la pregunta 5 aquí ###\n",
        "# Cargar el conjunto de datos Fashion MNIST\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Preprocesamiento de los datos\n",
        "num_classes = 10\n",
        "input_shape = (784,)  # 28x28 = 784\n",
        "\n",
        "# Definir la arquitectura de la red neuronal\n",
        "model = Sequential()\n",
        "model.add(Dense(128, activation='sigmoid', input_shape=input_shape))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Compilar el modelo\n",
        "optimizer = Adam()\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Mostrar la información del modelo\n",
        "model.summary()\n",
        "\n",
        "# Entrenar el modelo\n",
        "batch_size = 64\n",
        "epochs = 10\n",
        "history = model.fit(training_images, training_labels, batch_size=batch_size, epochs=epochs,\n",
        "                    verbose=1, validation_data=(test_images, test_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aNmrkkOZN6D"
      },
      "source": [
        "**Respuesta a la pregunta 5:**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si se quita la capa de aplanamiento (flatten) en una red neuronal que se entrena con imágenes, se producirá un error de forma (shape error) al intentar alimentar las imágenes en la red. Esto se debe a que la capa de aplanamiento es responsable de convertir la representación bidimensional de las imágenes en una representación unidimensional que puede ser procesada por las capas posteriores de la red neuronal.\n",
        "\n",
        "En el caso específico del código proporcionado anteriormente, la capa de aplanamiento (flatten) se encuentra después de la capa de convolución y antes de la capa completamente conectada (dense). Su propósito es convertir la salida de la capa de convolución en una representación plana (unidimensional) que puede ser alimentada a la capa completamente conectada para la clasificación final. Si se quita esta capa de aplanamiento, se producirá un error en la forma de los datos de entrada en la capa completamente conectada, ya que espera una representación plana pero recibiría una representación bidimensional de las imágenes de entrada.\n",
        "\n",
        "Por lo tanto, es importante mantener la capa de aplanamiento en la arquitectura de la red si se están utilizando imágenes como entrada para asegurar que los datos se procesen correctamente y se evite cualquier error de forma durante el entrenamiento o evaluación del modelo."
      ],
      "metadata": {
        "id": "QMKJVArKSBFy"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f37cIr81ZYJj"
      },
      "source": [
        "## 6: Número de neuronas de la capa de salida\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zk1xYVAQu0wN"
      },
      "source": [
        "Considerad la capa final, la de salida de la red neuronal de la pregunta 1.\n",
        "\n",
        "**pregunta 6.1 (0.25 puntos)**: ¿Por qué son 10 las neuronas de la última capa?\n",
        "\n",
        "**pregunta 6.2 (0.25 puntos)**: ¿Qué pasaría si tuvieras una cantidad diferente a 10? \n",
        "\n",
        "Por ejemplo, intenta entrenar la red con 5, para ello utiliza la red neuronal de la pregunta 1 y cambia a 5 el número de neuronas en la última capa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FhbZkppYZOCS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "314d5af9-bfc0-4302-8cdc-28d3e5cf67aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_16 (Dense)            (None, 128)               100480    \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 101,125\n",
            "Trainable params: 101,125\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-0fbc6938c47a>\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m history = model.fit(training_images, training_labels, batch_size=batch_size, epochs=epochs,\n\u001b[0m\u001b[1;32m     31\u001b[0m                     verbose=1, validation_data=(test_images, test_labels))\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1051, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1109, in compute_loss\n        return self.compiled_loss(\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/losses.py\", line 1984, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/usr/local/lib/python3.9/dist-packages/keras/backend.py\", line 5559, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 10) and (None, 5) are incompatible\n"
          ]
        }
      ],
      "source": [
        "### Tu código de la red neuronal con 5 neuronas en la capa de salida de la pregunta 7 aquí ###\n",
        "# Cargar el conjunto de datos Fashion MNIST\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Preprocesamiento de los datos\n",
        "num_classes = 10\n",
        "input_shape = (784,)  # 28x28 = 784\n",
        "\n",
        "# Aplanar las imágenes y convertir las etiquetas a one-hot encoding\n",
        "training_images = training_images.reshape(-1, 784).astype('float32') / 255.0\n",
        "test_images = test_images.reshape(-1, 784).astype('float32') / 255.0\n",
        "training_labels = to_categorical(training_labels, num_classes)\n",
        "test_labels = to_categorical(test_labels, num_classes)\n",
        "\n",
        "# Definir la arquitectura de la red neuronal\n",
        "model = Sequential()\n",
        "model.add(Dense(128, activation='sigmoid', input_shape=input_shape))\n",
        "model.add(Dense(5, activation='softmax'))\n",
        "\n",
        "# Compilar el modelo\n",
        "optimizer = Adam()\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Mostrar la información del modelo\n",
        "model.summary()\n",
        "\n",
        "# Entrenar el modelo\n",
        "batch_size = 64\n",
        "epochs = 10\n",
        "history = model.fit(training_images, training_labels, batch_size=batch_size, epochs=epochs,\n",
        "                    verbose=1, validation_data=(test_images, test_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLsQcq-6aUoD"
      },
      "source": [
        "**Respuesta a la pregunta 6.1:**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El número de neuronas en la última capa de la red neuronal se establece en 10 porque el conjunto de datos utilizado consta de 10 clases diferentes de prendas de vestir. Cada neurona en la capa de salida representa una clase específica, y la función de activación \"softmax\" se utiliza para obtener una distribución de probabilidad sobre las clases de salida. La clase con la probabilidad más alta se considera como la predicción final de la red para una imagen dada."
      ],
      "metadata": {
        "id": "sWOrRrN7Vum5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1f_7ZFeaUu6"
      },
      "source": [
        "**Respuesta a la pregunta 6.2:**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si se tuviera un número diferente de neuronas en la última capa de la red neuronal en comparación con el número de clases en el conjunto de datos, tendría algunas implicaciones:\n",
        "\n",
        "*   Error en la representación de las clases: Si se utiliza un número mayor o menor de neuronas en la capa de salida en comparación con el número de clases reales en el conjunto de datos, la red neuronal no sería capaz de representar adecuadamente todas las clases. Por ejemplo, si se usan solo 5 neuronas en la capa de salida para un conjunto de datos con 10 clases, habría una pérdida de información y algunas clases no serían representadas correctamente.\n",
        "*   Dificultad en la interpretación de las predicciones: El uso de un número incorrecto de neuronas en la capa de salida puede dificultar la interpretación de las predicciones del modelo. Si se usan más neuronas de las necesarias, las predicciones pueden ser menos confiables y más difíciles de entender en términos de qué clase específica se está prediciendo.\n",
        "*   Impacto en el rendimiento del modelo: El uso de un número inapropiado de neuronas en la capa de salida puede tener un impacto en el rendimiento del modelo. Si se usan menos neuronas de las necesarias, el modelo puede tener una capacidad de representación limitada y puede tener dificultades para alcanzar un alto nivel de precisión. Por otro lado, si se usan más neuronas de las necesarias, el modelo puede volverse más complejo y requerir más recursos computacionales para su entrenamiento y predicción.\n",
        "\n",
        "Por tanto, es importante asegurarse de que el número de neuronas en la última capa de la red neuronal coincida con el número de clases en el conjunto de datos para garantizar una representación adecuada de las clases, una interpretación clara de las predicciones y un rendimiento óptimo del modelo."
      ],
      "metadata": {
        "id": "rcUNn5jSWCGW"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNIBCkshaf2y"
      },
      "source": [
        "## 7: Aumento de epoch y su efecto en la red neuronal\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yg8tTqYPuwGc"
      },
      "source": [
        "En este ejercicio vamos a ver el impacto de aumentar los epoch en el entrenamiento. Usando la red neuronal de la pregunta 1:\n",
        "\n",
        "**pregunta 7.1 (0.15 puntos)**\n",
        "* Intentad 15 epoch para su entrenamiento, probablemente obtendras un modelo con una pérdida mucho mejor que el que tiene 5.\n",
        "\n",
        "**pregunta 7.2 (0.15 puntos)**\n",
        "* Intenta ahora con 30 epoch para su entrenamiento, podrás ver que el valor de la pérdida deja de disminuir, y a veces aumenta.\n",
        "\n",
        "**pregunta 7.3 (0.20 puntos)**\n",
        "* ¿Por qué piensas que ocurre esto? Explica tu respuesta y da el nombre de este efecto si lo conoces."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cb5vk_imG4iZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "729c7828-f0a3-482b-95ed-ce27a6c8626e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_22 (Dense)            (None, 128)               100480    \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 101,770\n",
            "Trainable params: 101,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "938/938 [==============================] - 17s 17ms/step - loss: 0.5927 - accuracy: 0.8046 - val_loss: 0.4637 - val_accuracy: 0.8332\n",
            "Epoch 2/15\n",
            "938/938 [==============================] - 25s 27ms/step - loss: 0.4105 - accuracy: 0.8545 - val_loss: 0.4228 - val_accuracy: 0.8494\n",
            "Epoch 3/15\n",
            "938/938 [==============================] - 21s 23ms/step - loss: 0.3727 - accuracy: 0.8668 - val_loss: 0.3972 - val_accuracy: 0.8613\n",
            "Epoch 4/15\n",
            "938/938 [==============================] - 20s 21ms/step - loss: 0.3485 - accuracy: 0.8744 - val_loss: 0.3859 - val_accuracy: 0.8626\n",
            "Epoch 5/15\n",
            "938/938 [==============================] - 20s 22ms/step - loss: 0.3320 - accuracy: 0.8794 - val_loss: 0.3763 - val_accuracy: 0.8683\n",
            "Epoch 6/15\n",
            "938/938 [==============================] - 19s 20ms/step - loss: 0.3152 - accuracy: 0.8859 - val_loss: 0.3625 - val_accuracy: 0.8703\n",
            "Epoch 7/15\n",
            "938/938 [==============================] - 27s 29ms/step - loss: 0.3024 - accuracy: 0.8903 - val_loss: 0.3486 - val_accuracy: 0.8769\n",
            "Epoch 8/15\n",
            "938/938 [==============================] - 21s 22ms/step - loss: 0.2913 - accuracy: 0.8934 - val_loss: 0.3494 - val_accuracy: 0.8734\n",
            "Epoch 9/15\n",
            "938/938 [==============================] - 21s 22ms/step - loss: 0.2814 - accuracy: 0.8973 - val_loss: 0.3350 - val_accuracy: 0.8770\n",
            "Epoch 10/15\n",
            "938/938 [==============================] - 21s 22ms/step - loss: 0.2731 - accuracy: 0.8999 - val_loss: 0.3355 - val_accuracy: 0.8805\n",
            "Epoch 11/15\n",
            "938/938 [==============================] - 18s 19ms/step - loss: 0.2635 - accuracy: 0.9044 - val_loss: 0.3384 - val_accuracy: 0.8746\n",
            "Epoch 12/15\n",
            "938/938 [==============================] - 19s 21ms/step - loss: 0.2555 - accuracy: 0.9069 - val_loss: 0.3350 - val_accuracy: 0.8831\n",
            "Epoch 13/15\n",
            "938/938 [==============================] - 21s 22ms/step - loss: 0.2496 - accuracy: 0.9085 - val_loss: 0.3234 - val_accuracy: 0.8863\n",
            "Epoch 14/15\n",
            "938/938 [==============================] - 16s 17ms/step - loss: 0.2418 - accuracy: 0.9115 - val_loss: 0.3274 - val_accuracy: 0.8822\n",
            "Epoch 15/15\n",
            "938/938 [==============================] - 16s 18ms/step - loss: 0.2357 - accuracy: 0.9144 - val_loss: 0.3282 - val_accuracy: 0.8817\n"
          ]
        }
      ],
      "source": [
        "### Tu código para 15 epoch aquí ###\n",
        "# Cargar el conjunto de datos Fashion MNIST\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Preprocesamiento de los datos\n",
        "num_classes = 10\n",
        "input_shape = (784,)  # 28x28 = 784\n",
        "\n",
        "# Aplanar las imágenes y convertir las etiquetas a one-hot encoding\n",
        "training_images = training_images.reshape(-1, 784).astype('float32') / 255.0\n",
        "test_images = test_images.reshape(-1, 784).astype('float32') / 255.0\n",
        "training_labels = to_categorical(training_labels, num_classes)\n",
        "test_labels = to_categorical(test_labels, num_classes)\n",
        "\n",
        "# Definir la arquitectura de la red neuronal\n",
        "model = Sequential()\n",
        "model.add(Dense(128, activation='sigmoid', input_shape=input_shape))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Compilar el modelo\n",
        "optimizer = Adam()\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Mostrar la información del modelo\n",
        "model.summary()\n",
        "\n",
        "# Entrenar el modelo\n",
        "batch_size = 64\n",
        "epochs = 15\n",
        "history = model.fit(training_images, training_labels, batch_size=batch_size, epochs=epochs,\n",
        "                    verbose=1, validation_data=(test_images, test_labels))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9jQ26Gda5cv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        },
        "outputId": "85c30108-0739-45c5-8d19-da52f9cb6732"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_24 (Dense)            (None, 128)               100480    \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 101,770\n",
            "Trainable params: 101,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "  1/938 [..............................] - ETA: 38:36 - loss: 2.5257 - accuracy: 0.0938"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-904eff34a759>\u001b[0m in \u001b[0;36m<cell line: 31>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m history = model.fit(training_images, training_labels, batch_size=batch_size, epochs=epochs,\n\u001b[0m\u001b[1;32m     32\u001b[0m                     verbose=1, validation_data=(test_images, test_labels))\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1654\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1655\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1656\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1657\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    473\u001b[0m         \"\"\"\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"end\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    320\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"end\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1093\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1168\u001b[0m             \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m             \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1170\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_finalize_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, current, values, finalize)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m             \u001b[0mio_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline_break\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m             \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/io_utils.py\u001b[0m in \u001b[0;36mprint_msg\u001b[0;34m(message, line_break)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mflush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    348\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m                 \u001b[0;31m# and give a timeout to avoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m                     \u001b[0;31m# write directly to __stderr__ instead of warning because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m                     \u001b[0;31m# if this is happening sys.stderr may be the problem.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    579\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "### Tu código para 30 epoch aquí ###\n",
        "### Tu código para 15 epoch aquí ###\n",
        "# Cargar el conjunto de datos Fashion MNIST\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Preprocesamiento de los datos\n",
        "num_classes = 10\n",
        "input_shape = (784,)  # 28x28 = 784\n",
        "\n",
        "# Aplanar las imágenes y convertir las etiquetas a one-hot encoding\n",
        "training_images = training_images.reshape(-1, 784).astype('float32') / 255.0\n",
        "test_images = test_images.reshape(-1, 784).astype('float32') / 255.0\n",
        "training_labels = to_categorical(training_labels, num_classes)\n",
        "test_labels = to_categorical(test_labels, num_classes)\n",
        "\n",
        "# Definir la arquitectura de la red neuronal\n",
        "model = Sequential()\n",
        "model.add(Dense(128, activation='sigmoid', input_shape=input_shape))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Compilar el modelo\n",
        "optimizer = Adam()\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Mostrar la información del modelo\n",
        "model.summary()\n",
        "\n",
        "# Entrenar el modelo\n",
        "batch_size = 64\n",
        "epochs = 30\n",
        "history = model.fit(training_images, training_labels, batch_size=batch_size, epochs=epochs,\n",
        "                    verbose=1, validation_data=(test_images, test_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fs0fjzH4bmSR"
      },
      "source": [
        "**Respuesta a la pregunta 7.3**:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cuando llegamos a un número de epochs en el que el valor de pérdida deja de disminuir y a veces aumenta, esto puede indicar que el modelo ha alcanzado su capacidad de aprendizaje óptima en los datos de entrenamiento y no está mejorando más. Este efecto se conoce como sobreajuste (overfitting) o sobreentrenamiento.\n",
        "\n",
        "El sobreajuste ocurre cuando el modelo se ajusta demasiado a los datos de entrenamiento, capturando ruido o detalles insignificantes en los datos en lugar de aprender patrones generales que se puedan aplicar a datos no vistos. Como resultado, el rendimiento del modelo puede degradarse en datos de prueba o en nuevos datos.\n",
        "\n",
        "El sobreajuste puede ocurrir cuando se utiliza un número excesivo de epochs en el entrenamiento del modelo. A medida que el modelo sigue ajustando sus pesos a los datos de entrenamiento, la pérdida en los datos de entrenamiento puede seguir disminuyendo. Sin embargo, llega a un punto en el que el modelo se vuelve demasiado especializado en los datos de entrenamiento y su capacidad de generalización a datos no vistos disminuye. Esto se refleja en un aumento de la pérdida en los datos de prueba o en nuevos datos."
      ],
      "metadata": {
        "id": "k1CmUo04YhN7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlIgNG4Yb_N6"
      },
      "source": [
        "## 8: Early stop\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06rrpDXqupAA"
      },
      "source": [
        "En el ejercicio anterior, cuando entrenabas con epoch extras, tenías un problema en el que tu pérdida podía cambiar. Puede que te haya llevado un poco de tiempo esperar a que el entrenamiento lo hiciera,  y puede que hayas pensado \"¿no estaría bien si pudiera parar el entrenamiento cuando alcance un valor deseado?\", es decir, una precisión del 85% podría ser suficiente para ti, y si alcanzas eso después de 3 epoch, ¿por qué sentarte a esperar a que termine muchas más épocas? Como cualquier otro programa existen formas de parar la ejecución\n",
        "\n",
        "A partir del código de ejemplo, hacer una nueva función que tenga en cuenta la perdida (loss) y que pueda parar el código para evitar que ocurra el efeto secundario que vimos en el ejercicio 5."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b5UwceFUG4ic"
      },
      "outputs": [],
      "source": [
        "### Ejemplo de código\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "      def on_epoch_end(self, epoch, logs={}):\n",
        "        if(logs.get('accuracy')> 0.85):\n",
        "              print(\"\\nAlcanzado el 85% de precisión, se cancela el entrenamiento!!\")\n",
        "              self.model.stop_training = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Bjd8wGKccrn"
      },
      "source": [
        "**Ejercicio 8 *(0.75 puntos)***: Completa el siguiente código con una clase callback que una vez alcanzado el 40% de perdida detenga el entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "29LSfdOvc270",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b06ef71-0bc4-48b8-a963-5abacabe8333"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.12.0\n",
            "Epoch 1/50\n",
            "   2/1875 [..............................] - ETA: 40:11 - loss: 2.2571 - accuracy: 0.2031"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0095s vs `on_train_batch_end` time: 0.2131s). Check your callbacks.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1868/1875 [============================>.] - ETA: 0s - loss: 0.4724 - accuracy: 0.8309\n",
            "Alcanzado el 40% de precisión, se cancela el entrenamiento!!\n",
            "1875/1875 [==============================] - 64s 33ms/step - loss: 0.4722 - accuracy: 0.8309\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1b82f4c2e0>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "### Tu código de la función callback para parar el entrenamiento de la red neuronal al 40% de loss aqui: ###\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "\n",
        "class myCallback(Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if logs.get('accuracy') > 0.40:\n",
        "            print(\"\\nAlcanzado el 40% de precisión, se cancela el entrenamiento!!\")\n",
        "            self.model.stop_training = True\n",
        "\n",
        "callbacks = myCallback()\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy']) \n",
        "\n",
        "model.fit(training_images, training_labels, epochs=50, callbacks=[callbacks])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_yZ9B8gTFqR"
      },
      "source": [
        "## 9. Unidades de activación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuVNxmXSTFqR"
      },
      "source": [
        "En este ejercicio, vamos a evaluar la importancia de utilizar las unidades de activación adecuadas. Como hemos visto en clase, funciones de activación como sigmoid han dejado de utilizarse en favor de otras unidades como ReLU.\n",
        "\n",
        "**Ejercicio 9 *(0.75 puntos)***: Partiendo de una red sencilla como la desarrollada en el Trabajo 1, escribir un breve análisis comparando la utilización de unidades sigmoid y ReLU (por ejemplo, se pueden comentar aspectos como velocidad de convergencia, métricas obtenidas...). Explicar por qué pueden darse estas diferencias. Opcionalmente, comparar con otras activaciones disponibles en Keras.\n",
        "\n",
        "*Pista: Usando redes más grandes se hace más sencillo apreciar las diferencias. Es mejor utilizar al menos 3 o 4 capas densas.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hoYUajTuTFqS"
      },
      "outputs": [],
      "source": [
        "## Tu código y comentarios de texto aquí\n",
        "## Puedes incluir tantas celdas como quieras\n",
        "## No olvides utilizar celdas de Markdown para texto"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pu6RbUFKTFqT"
      },
      "source": [
        "## 10. Inicialización de parámetros"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Abmm05UPTFqU"
      },
      "source": [
        "En este ejercicio, vamos a evaluar la importancia de una correcta inicialización de parámetros en una red neuronal.\n",
        "\n",
        "**Ejercicio 10 *(0.75 puntos)***: Partiendo de una red similar a la del ejercicio anterior (usando ya ReLUs), comentar las diferencias que se aprecian en el entrenamiento al utilizar distintas estrategias de inicialización de parámetros. Para ello, inicializar todas las capas con las siguientes estrategias, disponibles en Keras, y analizar sus diferencias:\n",
        "\n",
        "* Inicialización con ceros.\n",
        "* Inicialización con una variable aleatoria normal.\n",
        "* Inicialización con los valores por defecto de Keras para una capa Dense (estrategia *glorot uniform*)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qcMt7pSkTFqU"
      },
      "outputs": [],
      "source": [
        "## Tu código y comentarios de texto aquí\n",
        "## Puedes incluir tantas celdas como quieras\n",
        "## No olvides utilizar celdas de Markdown para texto"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqIAyVWrTFqV"
      },
      "source": [
        "## 11. Optimizadores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcYj29hYTFqW"
      },
      "source": [
        "**Ejercicio 11 *(0.75 puntos)***: Partiendo de una red similar a la del ejercicio anterior (utilizando la mejor estrategia de inicialización observada), comparar y analizar las diferencias que se observan  al entrenar con varios de los optimizadores vistos en clase, incluyendo SGD como optimizador básico (se puede explorar el espacio de hiperparámetros de cada optimizador, aunque para optimizadores más avanzados del estilo de adam y RMSprop es buena idea dejar los valores por defecto provistos por Keras)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fWDiqXvTFqW"
      },
      "outputs": [],
      "source": [
        "## Tu código y comentarios de texto aquí\n",
        "## Puedes incluir tantas celdas como quieras\n",
        "## No olvides utilizar celdas de Markdown para texto"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkfTFoJOTFqZ"
      },
      "source": [
        "## 12. Regularización y red final "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6CQhK7ZTFqZ"
      },
      "source": [
        "**Ejercicio 12 *(1 punto)***: Entrenar una red final que sea capaz de obtener una accuracy en el validation set cercana al 90%. Para ello, combinar todo lo aprendido anteriormente y utilizar técnicas de regularización para evitar overfitting. Algunos de los elementos que pueden tenerse en cuenta son los siguientes.\n",
        "\n",
        "* Número de capas y neuronas por capa\n",
        "* Optimizadores y sus parámetros\n",
        "* Batch size\n",
        "* Unidades de activación\n",
        "* Uso de capas dropout, regularización L2, regularización L1...\n",
        "* Early stopping (se puede aplicar como un callback de Keras, o se puede ver un poco \"a ojo\" cuándo el modelo empieza a caer en overfitting y seleccionar el número de epochs necesarias)\n",
        "* Batch normalization\n",
        "\n",
        "Si los modelos entrenados anteriormente ya se acercaban al valor requerido de accuracy, probar distintas estrategias igualmente y comentar los resultados.\n",
        "\n",
        "Explicar brevemente la estrategia seguida y los modelos probados para obtener el modelo final, que debe verse entrenado en este Notebook. No es necesario guardar el entrenamiento de todos los modelos que se han probado, es suficiente con explicar cómo se ha llegado al modelo final."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AUJ5AtunTFqa"
      },
      "outputs": [],
      "source": [
        "## Tu modelo y comentarios de texto aquí\n",
        "## Puedes incluir tantas celdas como quieras\n",
        "## No olvides utilizar celdas de Markdown para texto"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "GeO2xVqBv1fx",
        "BaqXlSMBwmMg"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}